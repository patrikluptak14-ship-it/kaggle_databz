# -*- coding: utf-8 -*-                                   # zabezpeƒç√≠ podporu slovensk√Ωch znakov v koment√°roch a v√Ωstupoch
"""
Kompletn√° anal√Ωza datasetu db1.csv pomocou pandas, numpy a sklearn.
- naƒç√≠tanie a presk√∫manie d√°t
- ƒçistenie a pr√≠prava
- v√Ωpoƒçty a vizualiz√°cie
- tr√©novanie modelov a predikcia
"""

# ===== 1. IMPORT KN√ç≈ΩNIC =====
import os                                                # pr√°ca so s√∫bormi a prieƒçinkami
import sys                                               # umo≈æn√≠ ukonƒçi≈• program ak nieƒço ch√Ωba
import numpy as np                                       # v√Ωpoƒçty s poƒæami a ƒç√≠slami
import pandas as pd                                      # pr√°ca s tabuƒækov√Ωmi d√°tami (DataFrame)
import matplotlib.pyplot as plt                          # kreslenie grafov

# kni≈ænice pre strojov√© uƒçenie zo sklearn
from sklearn.model_selection import train_test_split, cross_val_score   # rozdelenie d√°t a kr√≠≈æov√° valid√°cia
from sklearn.preprocessing import StandardScaler, LabelEncoder          # ≈°tandardiz√°cia ƒç√≠sel a k√≥dovanie textu
from sklearn.pipeline import Pipeline                                   # pipeline = viac krokov spracovania naraz
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # metriky v√Ωkonu modelu
from sklearn.linear_model import LogisticRegression                     # line√°rny klasifik√°tor
from sklearn.ensemble import RandomForestClassifier                     # stromov√Ω model
from sklearn.svm import SVC                                             # SVM klasifik√°tor

# ===== 2. KONFIGUR√ÅCIA =====
DATA_PATH = "db1.csv"                                    # n√°zov vstupn√©ho CSV s√∫boru
OUTPUT_DIR = "outputs"                                   # prieƒçinok pre ulo≈æenie v√Ωstupov (grafy, CSV)
TARGET_COL = None                                        # cieƒæov√Ω stƒ∫pec (label), None = skript ho sk√∫s√≠ n√°js≈• automaticky
TARGET_CANDIDATES = ["target", "label", "class", "species", "y"]  # n√°zvy, ktor√© skript hƒæad√° ako cieƒæov√©
RANDOM_STATE = 42                                        # seed = zaruƒç√≠, ≈æe v√Ωsledky bud√∫ st√°le rovnak√©

os.makedirs(OUTPUT_DIR, exist_ok=True)                  # ak prieƒçinok 'outputs' neexistuje, vytvor ho

# ===== 3. NAƒå√çTANIE D√ÅT =====
try:
    df = pd.read_csv(DATA_PATH)                         # naƒç√≠tanie CSV do DataFrame
except FileNotFoundError:                               # ak s√∫bor neexistuje
    sys.exit(f"Nen√°jden√Ω s√∫bor: {DATA_PATH}.")          # ukonƒç√≠ program s chybou

print("‚úÖ Dataset naƒç√≠tan√Ω:", DATA_PATH)                # info ≈æe s√∫bor bol naƒç√≠tan√Ω
print("\nüîé Uk√°≈æka d√°t:")
print(df.head())                                        # zobraz√≠ prv√Ωch 5 riadkov

print("\n‚ÑπÔ∏è Inform√°cie o d√°tach:")
print(df.info())                                        # info o poƒçte riadkov, stƒ∫pcov, typoch d√°t

print("\nüìä Z√°kladn√© ≈°tatistiky:")
print(df.describe(include='all'))                       # z√°kladn√© ≈°tatistiky ƒç√≠seln√Ωch aj textov√Ωch stƒ∫pcov

# ===== 4. ƒåISTENIE D√ÅT =====
rename_map_candidates = {                               # ak dataset pou≈æ√≠va in√© n√°zvy, tu ich m√¥≈æeme premenova≈•
    'sepal.length': 'sepal_length',
    'sepal.width': 'sepal_width',
    'petal.length': 'petal_length',
    'petal.width': 'petal_width',
    'variety': 'species',
    'class': 'species'
}
df = df.rename(columns=rename_map_candidates)           # premenovanie stƒ∫pcov podƒæa mapy vy≈°≈°ie

before = len(df)                                        # ulo≈æ√≠me si poƒçet riadkov pred odstr√°nen√≠m duplicit
df = df.drop_duplicates()                               # odstr√°nime duplicitn√© riadky
after = len(df)                                         # poƒçet riadkov po odstr√°nen√≠
print(f"\nüßπ Odstr√°nen√Ωch duplicitn√Ωch riadkov: {before - after}")

print("\nüìâ Poƒçet ch√Ωbaj√∫cich hodn√¥t:")
print(df.isnull().sum())                                # vyp√≠≈°eme poƒçet ch√Ωbaj√∫cich hodn√¥t v ka≈ædom stƒ∫pci

numeric_cols = df.select_dtypes(include=['number']).columns.tolist()  # n√°jdeme ƒç√≠seln√© stƒ∫pce
for col in numeric_cols:                                # pre ka≈æd√Ω ƒç√≠seln√Ω stƒ∫pec
    if df[col].isnull().any():                          # ak obsahuje ch√Ωbaj√∫ce hodnoty
        df[col] = df[col].fillna(df[col].median())      # dopln√≠me ich medi√°nom (robustn√© rie≈°enie)

# ===== 5. ≈†TATISTIKY + NUMPY TRANSFORM√ÅCIE =====
if len(numeric_cols) > 0:
    print("\nüìà ≈†tatistiky len pre ƒç√≠seln√© stƒ∫pce:")
    print(df[numeric_cols].describe())                  # z√°kladn√© ≈°tatistiky len pre ƒç√≠sla

# funkcia na min-max normaliz√°ciu (0 a≈æ 1)
def minmax_normalize(x: np.ndarray) -> np.ndarray:
    x = x.astype(float)                                 # pretypujeme na float
    mn, mx = np.nanmin(x), np.nanmax(x)                 # n√°jdeme min a max
    return np.zeros_like(x) if mx == mn else (x - mn) / (mx - mn)  # ak max = min, vr√°time nuly (inak v√Ωpoƒçet)

for col in numeric_cols:                                # pre ka≈æd√Ω ƒç√≠seln√Ω stƒ∫pec
    df[f"{col}_norm"] = minmax_normalize(df[col].to_numpy())  # prid√°me nov√Ω *_norm stƒ∫pec s normalizovan√Ωmi d√°tami

ref_col = numeric_cols[0] if len(numeric_cols) else None  # prv√Ω ƒç√≠seln√Ω stƒ∫pec zoberieme ako referenƒçn√Ω
if ref_col:
    arr = df[ref_col].to_numpy(dtype=float)            # prevedieme ho na numpy pole
    pct_change = np.empty_like(arr)                    # vytvor√≠me pr√°zdne pole rovnak√©ho tvaru
    pct_change[0] = np.nan                             # prv√Ω riadok nem√° predch√°dzaj√∫ci ‚Üí NaN
    denominator = np.where(arr[:-1] == 0, np.nan, arr[:-1])  # ak je predch√°dzaj√∫ca hodnota 0 ‚Üí NaN (delenie nulou)
    pct_change[1:] = (arr[1:] - arr[:-1]) / denominator * 100 # v√Ωpoƒçet percentu√°lnej zmeny
    df[f"{ref_col}_pct_change"] = pct_change           # ulo≈æ√≠me do nov√©ho stƒ∫pca

# ===== 6. FILTROVANIE, GROUPBY, GRAFY =====
if ref_col:
    mean_val = df[ref_col].mean()                      # priemern√° hodnota referenƒçn√©ho stƒ∫pca
    filtered = df[df[ref_col] > mean_val]              # filtrovanie: hodnoty v√§ƒç≈°ie ako priemer
    print(f"\nüìå Prv√Ωch 10 riadkov kde {ref_col} > priemer:")
    print(filtered.head(10))                           # uk√°≈æeme prv√Ωch 10

if 'species' in df.columns and len(numeric_cols) > 0:
    grouped = df.groupby('species')[numeric_cols].mean(numeric_only=True)  # priemery podƒæa skupiny 'species'
    print("\nüìä Priemery podƒæa 'species':")
    print(grouped)

# Histogram = rozdelenie hodn√¥t
plt.figure()
if ref_col:
    df[ref_col].hist()
    plt.title(f"Histogram - {ref_col}")
    plt.xlabel(ref_col)
    plt.ylabel("Frekvencia")
    plt.savefig(os.path.join(OUTPUT_DIR, f"hist_{ref_col}.png"))  # ulo≈æ√≠me graf
    plt.close()

# Boxplot = rozptyl d√°t
plt.figure()
if len(numeric_cols) >= 2:
    df.boxplot(column=list(numeric_cols[:2]))
    plt.title("Boxplot prv√Ωch dvoch ƒç√≠seln√Ωch stƒ∫pcov")
    plt.savefig(os.path.join(OUTPUT_DIR, "boxplot.png"))
    plt.close()

# Scatter = vz≈•ah dvoch ƒç√≠seln√Ωch premenn√Ωch
plt.figure()
if len(numeric_cols) >= 2:
    plt.scatter(df[numeric_cols[0]], df[numeric_cols[1]])
    plt.title(f"Scatter: {numeric_cols[0]} vs {numeric_cols[1]}")
    plt.xlabel(numeric_cols[0])
    plt.ylabel(numeric_cols[1])
    plt.savefig(os.path.join(OUTPUT_DIR, "scatter.png"))
    plt.close()

# ===== 7. KLASIFIK√ÅCIA =====
# funkcia, ktor√° sk√∫si automaticky n√°js≈• cieƒæov√Ω stƒ∫pec
def autodetect_target(dataframe, candidates):
    for c in candidates:
        if c in dataframe.columns:
            return c
    last = dataframe.columns[-1]                       # posledn√Ω stƒ∫pec ako z√°lo≈æn√Ω pl√°n
    if (dataframe[last].dtype == 'object') or (dataframe[last].nunique() <= 10):  # textov√Ω alebo m√°lo unik√°tov
        return last
    return None

if TARGET_COL is None:
    TARGET_COL = autodetect_target(df, TARGET_CANDIDATES)  # pokus o n√°jdenie cieƒæa

if TARGET_COL is None or TARGET_COL not in df.columns:
    print("\n‚ö†Ô∏è ≈Ωiadny cieƒæov√Ω stƒ∫pec ‚Äì klasifik√°cia sa preskoƒç√≠.")
    do_ml = False
else:
    do_ml = True

if do_ml:
    print(f"\nüéØ Cieƒæov√Ω stƒ∫pec: '{TARGET_COL}'")

    df = df.dropna(subset=[TARGET_COL])                # odstr√°nime riadky bez cieƒæa

    y_raw = df[TARGET_COL]                             # cieƒæov√Ω stƒ∫pec
    if y_raw.dtype == 'object':                        # ak je textov√Ω
        le = LabelEncoder()                            # prevedieme na ƒç√≠sla
        y = le.fit_transform(y_raw)
        classes_ = list(le.classes_)                   # n√°zvy tried
    else:
        y = y_raw.to_numpy()
        classes_ = sorted(list(pd.Series(y).unique()))

    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()  # n√°jdeme ƒç√≠seln√© vstupy
    feature_cols = [c for c in numeric_cols if c != TARGET_COL]           # X = v≈°etko okrem cieƒæa
    if len(feature_cols) == 0:
        print("‚ö†Ô∏è ≈Ωiadne ƒç√≠seln√© vstupy ‚Äì koniec ML.")
        do_ml = False

if do_ml:
    X = df[feature_cols].to_numpy(dtype=float)         # vstupn√© premenn√© ako numpy pole

    # rozdelenie na tr√©ningov√∫ (75 %) a testovaciu (25 %) mno≈æinu
    stratify_opt = y if pd.Series(y).nunique() > 1 else None
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=stratify_opt
    )

    # defin√≠cia 3 modelov
    models = {
        "LogReg": Pipeline([
            ("scaler", StandardScaler()),             # ≈°tandardiz√°cia d√°t
            ("clf", LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))
        ]),
        "RandomForest": Pipeline([
            ("clf", RandomForestClassifier(n_estimators=200, random_state=RANDOM_STATE))
        ]),
        "SVC": Pipeline([
            ("scaler", StandardScaler()),
            ("clf", SVC(kernel="rbf", probability=True, random_state=RANDOM_STATE))
        ])
    }

    results = []                                      # ulo≈æ√≠me v√Ωsledky modelov
    trained = {}                                      # ulo≈æ√≠me natr√©novan√© modely

    print("\nüß™ Tr√©ning a hodnotenie modelov:")
    for name, pipe in models.items():                 # iter√°cia cez v≈°etky modely
        pipe.fit(X_train, y_train)                    # tr√©ning modelu
        trained[name] = pipe

        y_pred = pipe.predict(X_test)                 # predikcia na testovacej mno≈æine
        acc = accuracy_score(y_test, y_pred)          # v√Ωpoƒçet presnosti
        results.append((name, acc))                   # ulo≈æenie v√Ωsledku

        print(f"\n‚Äî {name} ‚Äî")
        print("Presnos≈•:", round(acc, 4))
        print("Classification report:")
        print(classification_report(y_test, y_pred, zero_division=0, target_names=[str(c) for c in classes_]))

        try:
            cv_scores = cross_val_score(pipe, X, y, cv=5)  # 5-n√°sobn√° kr√≠≈æov√° valid√°cia
            print("CV sk√≥re:", round(cv_scores.mean(), 4), "¬±", round(cv_scores.std(), 4))
        except Exception as e:
            print("CV nespusten√©:", e)

        cm = confusion_matrix(y_test, y_pred)         # confusion matrix = matica ch√Ωb
        plt.figure()
        plt.imshow(cm, interpolation='nearest')
        plt.title(f"Confusion matrix - {name}")
        plt.xlabel("Predikovan√©")
        plt.ylabel("Skutoƒçn√©")
        plt.savefig(os.path.join(OUTPUT_DIR, f"cm_{name}.png"))
        plt.close()

    best_name, best_acc = sorted(results, key=lambda x: x[1], reverse=True)[0]  # n√°jdeme najlep≈°√≠ model
    best_model = trained[best_name]
    print(f"\nüèÜ Najlep≈°√≠ model: {best_name} (accuracy={round(best_acc, 4)})")

    if best_name == "RandomForest":                   # ak vyhr√° RandomForest, zobraz√≠me d√¥le≈æitos≈• znakov
        rf = best_model.named_steps["clf"]
        importances = getattr(rf, "feature_importances_", None)
        if importances is not None:
            fi = pd.Series(importances, index=feature_cols).sort_values(ascending=False)
            print("\nüîé D√¥le≈æitos≈• pr√≠znakov:")
            print(fi)

    n_preview = min(5, len(X_test))                   # uk√°≈æeme 5 predikci√≠
    preview_X = X_test[:n_preview]
    preview_true = y_test[:n_preview]
    preview_pred = best_model.predict(preview_X)

    def inv_label(vals):                              # funkcia na sp√§tn√© dek√≥dovanie textov√Ωch tried
        try:
            return le.inverse_transform(vals)
        except NameError:
            return vals

    preview_df = pd.DataFrame({
        "true": inv_label(preview_true),
        "pred": inv_label(preview_pred)
    })
    print("\nüîÆ Uk√°≈æka predikci√≠:")
    print(preview_df)

# ===== 8. ULO≈ΩENIE OƒåISTEN√ùCH D√ÅT =====
out_csv = os.path.join(OUTPUT_DIR, "db1_clean.csv")   # n√°zov v√Ωstupn√©ho CSV
df.to_csv(out_csv, index=False)                       # ulo≈æ√≠me DataFrame ako CSV
print(f"\nüíæ Oƒçisten√© d√°ta ulo≈æen√© do: {out_csv}")
print("\n‚úÖ HOTOVO.")                                 # hotovo!
